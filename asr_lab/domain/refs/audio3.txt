Токенизация играет важную роль при подготовке данных для языковых моделей.
